{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNER4IsUmzplBHlJPYA8dEp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/np03cs5a250002-cmyk/concept-and-technology-of-ai/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQon5TV2Y_SM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Sigmoid Function:"
      ],
      "metadata": {
        "id": "DRb5bGbzZKg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_function(x):\n",
        "  y= 1/(1+np.exp(-x))\n",
        "  return y"
      ],
      "metadata": {
        "id": "qDBzMV5MZDtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_logistic_function():\n",
        "  x_scalar= 0\n",
        "  expected_output_scalar= round(1 / (1 + np.exp(0)), 3)\n",
        "  print(expected_output_scalar)\n",
        "  assert round(logistic_function((x_scalar)),3)== expected_output_scalar ,'test failed for scalar input'\n",
        "\n",
        "  x_pos= 2\n",
        "  expected_output_pos = round(1 / (1 + np.exp(-2)), 3) # Expected output: ~0.881\n",
        "  assert round(logistic_function(x_pos), 3) == expected_output_pos, \"Test failed for positive scalarinput\"\n",
        "\n",
        "\n",
        "  x_neg = -3\n",
        "  expected_output_neg = round(1 / (1 + np.exp(3)), 3) # Expected output: ~0.047\n",
        "  assert round(logistic_function(x_neg), 3) == expected_output_neg, \"Test failed for negative scalar\"\n",
        "  # Test with numpy array input\n",
        "x_array = np.array([0, 2, -3])\n",
        "expected_output_array = np.array([0.5, 0.881, 0.047]) # Adjusted expected values rounded to 3 decimals\n",
        "# Use np.round to round the array element-wise and compare\n",
        "assert np.all(np.round(logistic_function(x_array), 3) == expected_output_array), \"Test failed for\"\n",
        "\n",
        "print(\"All tests passed!\")\n",
        "test_logistic_function()"
      ],
      "metadata": {
        "id": "fB90jrfiZVsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Log Loss Function:"
      ],
      "metadata": {
        "id": "JsNzmCw1ZajR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_loss(y_true, y_pred):\n",
        "  y_pred = np.clip(y_pred, 1e-10, 1 - 1e-10)\n",
        "  # print(y_pred)\n",
        "  loss= -(y_true*np.log(y_pred)+ (1-y_true)*np.log(1-y_pred))\n",
        "  return loss"
      ],
      "metadata": {
        "id": "1Wj-RB4eZcgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test function:\n",
        "y_true, y_pred = 0, 1\n",
        "\n",
        "print(f\"log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}\")\n",
        "print(\"+++++++++++++--------------------------++++++++++++++++++++++++\")\n",
        "y_true, y_pred = 1, 0.7\n",
        "print(f\"log loss({y_true}, {y_pred}) ==> {log_loss(y_true, y_pred)}\")\n",
        ""
      ],
      "metadata": {
        "id": "c2oPlcvAZgaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_log_loss():\n",
        "  y_true= 1\n",
        "  y_pred= 1\n",
        "  expected_loss= 0.0\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss),\"test failed for y_true= 1 and y_pred= 1 \"\n",
        "  print(\"sucessfull 1\")\n",
        "\n",
        "  y_true= 0\n",
        "  y_pred= 0\n",
        "  expected_loss= 0.0\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss),\"test failed for y_true= 0 and y_pred= 0 \"\n",
        "  print(\"sucessfull 2\")\n",
        "\n",
        "\n",
        "  y_true = 1\n",
        "  y_pred = 0\n",
        "\n",
        "  try:\n",
        "    log_loss(y_true, y_pred) # This should raise an error due to log(0)\n",
        "  except ValueError:\n",
        "    pass # Test passed if ValueError is raised for log(0)\n",
        "\n",
        "# Test case 4: Incorrect prediction (y_true = 0, y_pred = 1)\n",
        "  y_true = 0\n",
        "  y_pred = 1\n",
        "  try:\n",
        "    log_loss(y_true, y_pred) # This should raise an error due to log(0)\n",
        "  except ValueError:\n",
        "    pass # Test passed if ValueError is raised for log(0)\n",
        "  y_true = 1\n",
        "  y_pred = 0.8\n",
        "  expected_loss = -(1 * np.log(0.8)) - (0 * np.log(0.2)) # ~0.2231\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for partiallycorrect prediction (y_true=1, y_pred=0.8)\"\n",
        "  y_true = 0\n",
        "  y_pred = 0.2\n",
        "  expected_loss = -(0 * np.log(0.2)) - (1 * np.log(0.8)) # ~0.2231\n",
        "  assert np.isclose(log_loss(y_true, y_pred), expected_loss, atol=1e-6), \"Test failed for partiallycorrect prediction (y_true=0, y_pred=0.2)\"\n",
        "  print(\"All test passed\")\n",
        "\n",
        "\n",
        "\n",
        "test_log_loss()"
      ],
      "metadata": {
        "id": "Zx95seJWZkeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Cost Function:"
      ],
      "metadata": {
        "id": "s2XdLUujZ3z5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost_function(y_true, y_pred):\n",
        "  assert len(y_true)==len(y_pred),\"length of value and predicted must be equal\"\n",
        "  n= len(y_true)\n",
        "  loss_vec=log_loss(y_true, y_pred)\n",
        "  cost= np.sum(loss_vec)/ n\n",
        "  return cost\n",
        "\n",
        "\n",
        "# testing the cost function\n",
        "def test_cost_function():\n",
        "  y_true=np.array([1,0,1])\n",
        "  y_pred= np.array([0.9,0.1,0.8])\n",
        "\n",
        "  expected_cost = (-(1 * np.log(0.9)) - (1 - 1) * np.log(1 - 0.9) +\n",
        "  -(0 * np.log(0.1)) - (1 - 0) * np.log(1 - 0.1) +\n",
        "  -(1 * np.log(0.8)) - (1 - 1) * np.log(1 - 0.8)) / 3\n",
        "\n",
        "  result= cost_function(y_true,y_pred)\n",
        "  # print(result,'result is ')\n",
        "  # print(expected_cost,'expected_cost is ')\n",
        "  #if the difference between this two output is less than or equal to 1e-0 then it is considerable\n",
        "  assert np.isclose(result, expected_cost, atol=1e-6), f\"Test failed: {result} != {expected_cost}\"\n",
        "  print(\"Test passed for simple case!\")\n",
        "test_cost_function()\n"
      ],
      "metadata": {
        "id": "eF8W_p61Z0sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def costfunction_logreg(X,Y,W,B):\n",
        "  # print(X.shape,\"X\")\n",
        "  # print(Y.shape,\"Y\")\n",
        "  # print(W.shape,\"W\")\n",
        "  # n= rows\n",
        "  # d= columns\n",
        "  n,d= X.shape\n",
        "  # print('n',n)\n",
        "  # print('d',d)\n",
        "\n",
        "  assert len(Y)==n,\"Number of feature observations and number of target observations do not match.\"\n",
        "  assert len(W) == d, \"Number of features and number of weight parameters do not match.\"\n",
        "  Z= np.dot(X,W)+B\n",
        "  y_pred= 1/(1+np.exp(-Z))\n",
        "  cost= cost_function(Y,y_pred)\n",
        "  return cost\n",
        "\n",
        "X=np.array([[10, 20], [-10, 10]])\n",
        "Y=np.array([1, 0])\n",
        "W=np.array([0.5, 1.5])\n",
        "B=1\n",
        "print(f\"the cost function is {costfunction_logreg(X,Y,W,B):.4f}\")\n",
        "print(X)"
      ],
      "metadata": {
        "id": "Zj2lZSQnZ980"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X,Y,W,B):\n",
        "  # print(X.shape,\"X\")\n",
        "  # print(Y.shape,\"Y\")\n",
        "\n",
        "  # print(W.shape,\"W\")\n",
        "\n",
        "  n,d= X.shape\n",
        "  M= len(Y)\n",
        "  assert len(Y)==n ,\"y and n dont have equal length means label are not equal according to row \"\n",
        "  assert len(W)==d,\"w and d dont have equal length means weight is not equal to all columns\"\n",
        "  Z= np.dot(X,W)+B\n",
        "  y_pred= 1/(1+np.exp(-Z))\n",
        "  error= y_pred -Y\n",
        "  dot_product= np.dot(X.T ,error)\n",
        "  grad_W= np.sum(dot_product)/M\n",
        "  grad_B= (np.sum(error))/M\n",
        "  return grad_W, grad_B\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = np.array([[10, 20], [-10, 10]]) # shape (2, 2)\n",
        "Y = np.array([1, 0]) # shape (2,)\n",
        "W = np.array([0.5, 1.5]) # shape (2,)\n",
        "B = 1 # scalar\n",
        "\n",
        "try:\n",
        "  grad_w, grad_b = compute_gradient(X, Y,W, B)\n",
        "  print(\"Gradients computed successfully.\")\n",
        "  print(f\"grad_w: {grad_w}\")\n",
        "  print(f\"grad_b: {grad_b}\")\n",
        "except AssertionError as e:\n",
        "  print(f\"Assertion error: {e}\")"
      ],
      "metadata": {
        "id": "pi3YiI9SaCuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testig for gradient descent\n",
        "def test_gradient_descent():\n",
        "  x= np.array([[0.1, 0.2], [-0.1, 0.1]])\n",
        "  y = np.array([1, 0])\n",
        "  w= np.zeros(x.shape[1])\n",
        "  print(w)\n",
        "  b=0.0\n",
        "  alpha = 0.5\n",
        "  n_itr=  100000\n",
        "  w_out, b_out, cost_history,params_history,i_values= gradient_descent(x,y,w,b,alpha,n_itr,show_cost=False,show_params=False)\n",
        "\n",
        "  assert len(cost_history) == n_itr, \"Cost history length does not match the number of iterations\"\n",
        "  assert w_out.shape == w.shape, \"Shape of output weights does not match the initial weights\"\n",
        "  assert isinstance(b_out, float), \"Bias output is not a float\"\n",
        "  assert cost_history[-1] < cost_history[0], \"Cost did not decrease over iterations\"\n",
        "  print(f'final cost function is {cost_history[-1]}')\n",
        "  print(f'second last  cost function is {cost_history[-2]}')\n",
        "  print(f\"difference in cost function {cost_history[-2]- cost_history[-1]:.4f}\")\n",
        "  print(\"All tests passed!\")\n",
        "test_gradient_descent()"
      ],
      "metadata": {
        "id": "SUJ0SmuYaDy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (9, 6))\n",
        "plt.plot(cost_history)\n",
        "plt.xlabel(\"Iteration\", fontsize = 14)\n",
        "plt.ylabel(\"Cost\", fontsize = 14)\n",
        "plt.title(\"Cost vs Iteration\", fontsize = 14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3KS9CXzwaLE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision/Prediction Function for Binary Classification:\n",
        "our threshold is 0.5 yˆ = ( 1 if yprob ≥ τ, 0 if yprob < τ. )"
      ],
      "metadata": {
        "id": "oEtXv3G4aRo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(X,W,B,threshold=0.5):\n",
        "  Z= np.dot(X,W)+B\n",
        "  print(Z)\n",
        "  print(X)\n",
        "  y_test_prob= 1/(1+np.exp(-Z))\n",
        "  y_pred = (y_test_prob >= threshold).astype(int)\n",
        "  # as type(int) gives the true or false if true it is 1 and if false then 0\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "\n",
        "def test_predicition():\n",
        "  X_test = np.array([[0.5, 1.0], [1.5, -0.5], [-0.5, -1.0]]) # Shape (3, 2)\n",
        "  w_test = np.array([1.0, -1.0]) # Shape (2,)\n",
        "  b_test = 0.0 # Scalar bias\n",
        "  threshold= 0.5\n",
        "  expected_output = np.array([0, 1, 1])\n",
        "  y_pred = prediction(X_test, w_test, b_test, threshold)\n",
        "  print(\"prediction is \",y_pred)\n",
        "  assert np.array_equal(y_pred, expected_output), f\"Expected {expected_output}, but got {y_pred}\"\n",
        "\n",
        "  print(\"test passed\")\n",
        "test_predicition()"
      ],
      "metadata": {
        "id": "jz8ryoVZaOlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classification(y_true, y_pred):\n",
        "  TP = np.sum((y_true == 1) & (y_pred == 1)) # True Positives\n",
        "  TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "  FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "  FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "# Confusion matrix\n",
        "  confusion_matrix = np.array([[TN, FP],[FN, TP]])\n",
        "  precision = TP / (TP + FP) if (TP + FP) > 0.0 else 0.0\n",
        "  recall = TP / (TP + FN) if (TP + FN) > 0.0 else 0.0\n",
        "  f1_score = (2*recall*precision)/(recall+precision)\n",
        "# Metrics dictionary\n",
        "  metrics = {\n",
        "  \"confusion_matrix\": confusion_matrix,\n",
        "  \"precision\": precision,\n",
        "  \"recall\": recall,\n",
        "  \"f1_score\": f1_score\n",
        "  }\n",
        "  return metrics\n",
        "y_true=np.array([1,0,1])\n",
        "y_pred= np.array([1,1,0])\n",
        "print(evaluate_classification(y_true, y_pred))"
      ],
      "metadata": {
        "id": "kqMiOpl4aVxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Basic Data Operation, Loading, Analysis and Cleaning:"
      ],
      "metadata": {
        "id": "m4iPAtWrajno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "url = \"/content/drive/MyDrive/diabetes_.csv\"\n",
        "columns = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
        "data_pima_diabetes = pd.read_csv(url, header=0)\n",
        "\n",
        "columns_to_clean = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
        "\n",
        "data_pima_diabetes[columns_to_clean] = data_pima_diabetes[columns_to_clean].replace(0, np.nan)\n",
        "\n",
        "data_pima_diabetes[columns_to_clean] = data_pima_diabetes[columns_to_clean].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "data_pima_diabetes[columns_to_clean] = data_pima_diabetes[columns_to_clean].fillna(\n",
        "    data_pima_diabetes[columns_to_clean].median()\n",
        ")\n",
        "\n",
        "data_pima_diabetes.info()\n",
        "data_pima_diabetes.describe()"
      ],
      "metadata": {
        "id": "C2NLUaz0aaBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Test Split and Standard Scaling of the Data:"
      ],
      "metadata": {
        "id": "R5kYXRVvasLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X= data_pima_diabetes.drop(columns=['Outcome']).values\n",
        "Y= data_pima_diabetes['Outcome'].values\n",
        "X_train,X_test, Y_train,Y_test= train_test_split(X,Y)\n",
        "print(\"X_train\",X_train.shape)\n",
        "print(\"X_test\",X_test.shape)\n",
        "print(\"Y_train\",Y_train.shape)\n",
        "print(\"Y_test\",Y_test.shape)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "print(X_train_scaled.shape)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "r-gKBmtLati9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training of the Sigmoid Regression:"
      ],
      "metadata": {
        "id": "nOPwlClpa0uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = np.zeros(X_train_scaled.shape[1])\n",
        "b = 0.0\n",
        "alpha = 0.1\n",
        "n_iter = 1000\n",
        "print(\"\\nTraining Logistic Regression Model:\")\n",
        "w, b, cost_history,params_history,i_values = gradient_descent(X_train_scaled, Y_train, w, b, alpha, n_iter,show_cost=True, show_params=False)\n",
        "# Plot cost history\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(cost_history)\n",
        "plt.xlabel(\"Iteration\", fontsize=14)\n",
        "plt.ylabel(\"Cost\", fontsize=14)\n",
        "plt.title(\"Cost vs Iteration\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2v7IxOcVaxhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred= prediction(X_train_scaled,w,b,threshold=0.5)\n",
        "y_test_pred= prediction(X_test_scaled,w,b,threshold=0.5)\n",
        "train_cost= costfunction_logreg (X_train_scaled, Y_train, w,b)\n",
        "test_cost= costfunction_logreg (X_test_scaled, Y_test, w,b)\n",
        "print(f\"\\nTrain Loss (Cost): {train_cost:.4f}\")\n",
        "print(f\"Test Loss (Cost): {test_cost:.4f}\")"
      ],
      "metadata": {
        "id": "hvuLy2RGa-CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "test_accuracy = np.mean(y_test_pred == Y_test) * 100\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Confusion matrix and metrics\n",
        "cm = confusion_matrix(Y_test, y_test_pred)\n",
        "precision = precision_score(Y_test, y_test_pred)\n",
        "recall = recall_score(Y_test, y_test_pred)\n",
        "f1 = f1_score(Y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "\n",
        "# Visualization\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.imshow(cm, cmap=\"Blues\")   # <-- numeric array now\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=(\"Predicted 0s\", \"Predicted 1s\"))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=(\"Actual 0s\", \"Actual 1s\"))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"white\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zi59i0Wha_3R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}