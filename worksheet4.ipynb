{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lBxUeUae534DZi6PgrIrWuttqhqNX-XA",
      "authorship_tag": "ABX9TyMGenUg23dvv41i/1PE7+JC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/np03cs5a250002-cmyk/concept-and-technology-of-ai/blob/main/worksheet4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2UzL8R0WR2fZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the Dataset:\n",
        "df= pd.read_csv(\"/content/drive/MyDrive/diabetes_.csv\")\n",
        "#df.head()\n",
        "#df.tail()\n",
        "#df.describe()\n",
        "null_values= df.isnull().sum()\n",
        "print(f\"{null_values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "8gleZCM_TzwQ",
        "outputId": "f60512d7-0f9a-4e96-80bb-2e36516a4a0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/diabetes_.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3013455695.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load the Dataset:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/diabetes_.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#df.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df.tail()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df.describe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/diabetes_.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle any missing values appropriately, either by dropping or imputing them based on the data.\n",
        "missing_values= df.isnull().sum()/len(df)*100\n",
        "for column in df.columns:\n",
        "  if missing_values[column]>10:\n",
        "    df[column].fillna(df[column].mean(),inplace=True)\n",
        "  else:\n",
        "    df.dropna(subset=[column],inplace=True)\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "FVwItm74T3_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= df.drop(columns=\"Outcome\").values\n",
        "Y= df[\"Outcome\"].values\n",
        "#print(X.shape[0])\n",
        "#print(int(len(X) *0.3))\n",
        "def train_test_split_scratch(X,Y, test_size=0.3, seed=42):\n",
        "   #the sequence of random numbers will always be the same every time you run the program\n",
        "\n",
        "   np.random.seed(seed)\n",
        "   indices= np.arange(X.shape[0]) #prints the number from 0 to 767\n",
        "   np.random.shuffle(indices) #shuffle\n",
        "   test_split_size= int(len(X) *test_size)\n",
        "   test_idx= indices[:test_split_size]\n",
        "   train_idx= indices[test_split_size:]\n",
        "   X_train= X[train_idx]\n",
        "   X_test= X[test_idx]\n",
        "   Y_train=Y[train_idx]\n",
        "   Y_test=Y[test_idx]\n",
        "   return X_train,X_test,Y_train,Y_test\n",
        "X_train, X_test, Y_train, Y_test = train_test_split_scratch(X, Y)\n",
        "print(f\"Xtrain shape {X_train.shape}\")\n",
        "print(f\"Xtest shape {X_test.shape}\")\n",
        "print(f\"Ytrain shape {Y_train.shape}\")\n",
        "print(f\"Ytest shape {Y_test.shape}\")\n",
        "\n",
        "\n",
        "# implementing KNN\n",
        "def Encludiean_distance(a,b):\n",
        "  return np.sqrt(np.sum((a-b)**2))\n",
        "\n",
        "#Predicting the class for a single query.\n",
        "def knn_predict_single (x, X_train, Y_train,k=3):\n",
        "  distances = []\n",
        "  for point in X_train:\n",
        "      distances.append(Encludiean_distance(x, point))\n",
        "  sorted_indx= np.argsort(distances)\n",
        "  nearest_index=sorted_indx[:k]\n",
        "  nearest_labels= Y_train[nearest_index]\n",
        "  #finds the most frequent value in an array\n",
        "\n",
        "  prediction= np.bincount(nearest_labels).argmax()\n",
        "  return prediction\n",
        "\n",
        "#Predicting classes for all test samples.\n",
        "def knn_predict(X_test, X_train , Y_train, k=3):\n",
        "  preds=[]\n",
        "  for sample in X_test:\n",
        "      preds.append(knn_predict_single(sample, X_train, Y_train,k ))\n",
        "  return np.array(preds)\n",
        "\n",
        "#performance accuracy\n",
        "def compute_accuracy(y_true, y_pred):\n",
        "  correctvalues= np.sum(y_true==y_pred)\n",
        "  return (correctvalues/len(y_true)*100)\n",
        "\n",
        "predictions = knn_predict(X_test, X_train, Y_train, k=5)\n",
        "\n",
        "accuracy = compute_accuracy(Y_test, predictions)\n",
        "print(\" Predictions:\", predictions[:5])\n",
        "print(f\"the accuracy is {accuracy} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "uGlmRTi9T_uF",
        "outputId": "db5818f2-4707-4eb8-b07f-d5232046b828"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-938756762.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Outcome\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Outcome\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(X.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(int(len(X) *0.3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_test_split_scratch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "problem 2\n",
        "Xscaled​= X-mean(x) /std(x)"
      ],
      "metadata": {
        "id": "DHxDi9miUEQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_mean= X_train.mean(axis=0)\n",
        "X_std= X_train.std(axis=0)\n",
        "X_std[X_std==0]=1\n",
        "X_train_scaled=(X_train -  X_mean)/X_std\n",
        "X_test_scaled=(X_test -  X_mean)/X_std\n",
        "#print(f\"x train scaled is \\n {X_train_scaled[:3]}\")\n",
        "#print(f\"x test scaled is \\n {X_test_scaled[:3]}\")\n",
        "prediction_scale= knn_predict(X_test_scaled,X_train_scaled,Y_train, k=3)\n",
        "accuracy_scale= compute_accuracy(Y_test,prediction_scale )\n",
        "print(f\"before unscaled prediction {accuracy}\")\n",
        "print(f\"after scaled prediction {accuracy_scale}\")\n",
        "\n",
        "#• Discuss:\n",
        "# How scaling impacted the KNN performance.\n",
        "# The reason for any observed changes in accuracy.\n",
        "print(f''' \\n here before scaling the accuracy is {accuracy}\n",
        "but after scaling the prediction is {accuracy_scale}\n",
        "so the accuracy differ by {accuracy_scale-accuracy}''')\n",
        "print('''\n",
        "the accuracy increased becuase:\n",
        "- More meaningful nearest neighbors\n",
        "- Better separation between classes\n",
        "- Improved accuracy and generalization\n",
        "\n",
        "\n",
        "''')"
      ],
      "metadata": {
        "id": "3gjXhyt_UFSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem - 3 - Experimentation with k:"
      ],
      "metadata": {
        "id": "Jc7pjruIUNya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k_values= range(1,16)\n",
        "print(k_values)\n",
        "import time\n",
        "scaled_accuracy= []\n",
        "unscaled_accuracy= []\n",
        "time_unscaled=[]\n",
        "time_scaled=[]\n",
        "for kk in k_values:\n",
        "  #unscalad\n",
        "  unscaled_pred= knn_predict(X_test,X_train,Y_train, kk)\n",
        "  unscaled_accuracy.append(compute_accuracy(Y_test, unscaled_pred))\n",
        "\n",
        "\n",
        "  #scaled\n",
        "  scaled_pred= knn_predict(X_test_scaled,X_train_scaled,Y_train, kk)\n",
        "  scaled_accuracy.append(compute_accuracy(Y_test, scaled_pred))\n",
        "\n",
        "  #time\n",
        "\n",
        "  #unscaled\n",
        "  t1= time.time()\n",
        "  knn_predict(X_test,X_train,Y_train, kk)\n",
        "  t2= time.time()\n",
        "  time_unscaled.append(t2 - t1)\n",
        "  #scaled\n",
        "  t3= time.time()\n",
        "  knn_predict(X_test_scaled,X_train_scaled,Y_train, kk)\n",
        "  t4= time.time()\n",
        "  time_scaled.append(t4-t3)\n",
        "\n",
        "# plotting graph\n",
        "plt.plot(k_values,unscaled_accuracy, marker='o',label='unscaled', color='red')\n",
        "plt.plot(k_values,scaled_accuracy, marker='o',label='scaled')\n",
        "plt.xlabel('k')\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"K vs Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "D6eagyqoUKWc",
        "outputId": "a87514b0-c64e-476a-8b40-71ba0278475c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "range(1, 16)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'knn_predict' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-464845851.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#unscalad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0munscaled_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mknn_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0munscaled_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munscaled_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'knn_predict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(k_values, time_unscaled, marker='o', label='Unscaled_time')\n",
        "plt.plot(k_values, time_scaled, marker='x', label='Scaled_time')\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Time (seconds)\")\n",
        "plt.title(\"k vs Time\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IjgajddkV1Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkAjGMr2bMz"
      },
      "source": [
        "• Discuss how the choice of k affects the accuracy and computational cost.\n",
        "\n",
        "As we see, when the k is too small (1,2,3..) accuracy is usually lower and unstable becuase the model become too sensitive and it reads the noise too so one wrong neighbour can change the prediction. so, when the k is increase the accuracy gradually improves and become more stable becuase more neighbours vote reduce the influence of noise.\n",
        "\n",
        "In conclusion:\n",
        "when the value of k increase, the accuracy is also increasing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Identify the optimal k based on your analysis.\n",
        "\n",
        "the highest accuracy occurs around k= 15 because the scaled accuracy is more than 75%-80% so we can say that optimal k is 12-15"
      ],
      "metadata": {
        "id": "JhnN99OHWd0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem - 4 - Additional Questions {Optional - But Highly Recommended}:\n",
        "\n",
        "• Discuss the challenges of using KNN for large datasets and high-dimensional data.\n",
        "\n",
        "challenges are:\n",
        "\n",
        "kNN can be computationally expensive due to the need to calculate distances for all training examples. Storage and memory requirements can be significant, especially with pre-sorting and large datasets. High-dimensional data exacerbates computational costs and performance due to the ”curse of dimensionality.” Efficient data handling techniques (e.g., LSH, condensing) and dimensionality reduction methods are essential for optimizing kNN performance. When d ≫ 0 (i.e., when the number of dimensions is very large), points drawn from a probability distribution start to lose similarity, causing the kNN assumption to break down."
      ],
      "metadata": {
        "id": "KwHE9zXwWqMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Suggest strategies to improve the efficiency of KNN (e.g., approximate nearest neighbors, dimensionality\n",
        "reduction)\n",
        "\n",
        "improvement are:\n",
        "\n",
        "Dimensionality reduction\n",
        "\n",
        "use efficient data structure\n",
        "\n",
        "reduce dataset\n",
        "\n",
        "remove irrelevant or noisy features\n",
        "\n"
      ],
      "metadata": {
        "id": "AHoZK4raWsko"
      }
    }
  ]
}