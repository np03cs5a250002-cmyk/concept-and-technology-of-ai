{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1pEn5HQMBaP_QcIiwgiubaDDOGy-FL5Wy",
      "authorship_tag": "ABX9TyOZcXhH3bsWaPDlwUzvKhtY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/np03cs5a250002-cmyk/concept-and-technology-of-ai/blob/main/AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment I : Statistical Interpretation and Exploratory Data Analysis\n",
        "Analysis of the Human Development Index (HDI)\n",
        "\n",
        "Course: Concepts and Technologies of AI (5CS037)\n",
        "Student Name: Prayash paoudel\n",
        "Student ID:\n",
        "Dataset: Human_Development_Index_Dataset.csv\n",
        "Submission Date: 10 January, 2026\n"
      ],
      "metadata": {
        "id": "08sFsR7kqtYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table of Contents\n",
        "1. Problem 1A: Exploration of Single Year HDI (2022)\n",
        "2. Problem 1B: HDI Trend Analysis (2020–2022)\n",
        "3. Problem 2: Advanced HDI Exploration (South Asia)\n",
        "4. Problem 3: Comparative Regional Analysis"
      ],
      "metadata": {
        "id": "Ns9gbemTq02e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. Problem 1A – Exploration of Single Year HDI  (2022)\n"
      ],
      "metadata": {
        "id": "nSQWHLW3q5YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1: Extract Latest Year (2022)"
      ],
      "metadata": {
        "id": "DV93E2mOrcBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "1WoT0gNWc0d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/MyDrive/\"\n",
        "df = pd.read_csv(file_path, encoding=\"latin1\")"
      ],
      "metadata": {
        "id": "8wbkCIgqc4Ii",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "cfbc1720-7bf4-4759-ab1b-45927c2e76bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/MyDrive/'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3769102790.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/MyDrive/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/MyDrive/'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.lower().str.strip().str.replace(' ', '_')\n",
        "\n",
        "# 3. Define Region Mapping\n",
        "# We need specific regions: \"South Asia\" and \"Middle East\".\n",
        "# For the rest, we will map to broader continents to make Problem 1B meaningful.\n",
        "\n",
        "iso_to_region = {\n",
        "    # South Asia\n",
        "    'AFG': 'South Asia', 'BGD': 'South Asia', 'BTN': 'South Asia', 'IND': 'South Asia',\n",
        "    'IRN': 'South Asia', 'MDV': 'South Asia', 'NPL': 'South Asia', 'PAK': 'South Asia', 'LKA': 'South Asia',\n",
        "\n",
        "    # Middle East (Western Asia + North Africa typically)\n",
        "    'ARE': 'Middle East', 'BHR': 'Middle East', 'DJI': 'Middle East', 'DZA': 'Middle East',\n",
        "    'EGY': 'Middle East', 'IRQ': 'Middle East', 'JOR': 'Middle East', 'KWT': 'Middle East',\n",
        "    'LBN': 'Middle East', 'LBY': 'Middle East', 'MAR': 'Middle East', 'OMN': 'Middle East',\n",
        "    'PSE': 'Middle East', 'QAT': 'Middle East', 'SAU': 'Middle East', 'SYR': 'Middle East',\n",
        "    'TUN': 'Middle East', 'YEM': 'Middle East', 'TUR': 'Middle East', 'ISR': 'Middle East',\n",
        "\n",
        "    # North America\n",
        "    'USA': 'North America', 'CAN': 'North America', 'MEX': 'North America',\n",
        "\n",
        "    # Europe (Sample of major ones)\n",
        "    'GBR': 'Europe', 'FRA': 'Europe', 'DEU': 'Europe', 'ITA': 'Europe', 'ESP': 'Europe',\n",
        "    'NOR': 'Europe', 'SWE': 'Europe', 'DNK': 'Europe', 'FIN': 'Europe', 'ISL': 'Europe',\n",
        "    'RUS': 'Europe', 'UKR': 'Europe', 'POL': 'Europe', 'NLD': 'Europe', 'BEL': 'Europe',\n",
        "    'CHE': 'Europe', 'AUT': 'Europe', 'PRT': 'Europe', 'GRC': 'Europe', 'IRL': 'Europe',\n",
        "\n",
        "    # East Asia & Pacific\n",
        "    'CHN': 'East Asia', 'JPN': 'East Asia', 'KOR': 'East Asia', 'PRK': 'East Asia',\n",
        "    'MNG': 'East Asia', 'AUS': 'Oceania', 'NZL': 'Oceania',\n",
        "\n",
        "    # Sub-Saharan Africa (Sample)\n",
        "    'ZAF': 'Sub-Saharan Africa', 'NGA': 'Sub-Saharan Africa', 'KEN': 'Sub-Saharan Africa',\n",
        "    'ETH': 'Sub-Saharan Africa', 'GHA': 'Sub-Saharan Africa',\n",
        "\n",
        "    # South America\n",
        "    'BRA': 'South America', 'ARG': 'South America', 'CHL': 'South America',\n",
        "    'COL': 'South America', 'PER': 'South America'\n",
        "}"
      ],
      "metadata": {
        "id": "PYLKLt08eDbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_region(iso_code):\n",
        "    return iso_to_region.get(iso_code, 'Rest of World')\n",
        "\n",
        "# Apply mapping\n",
        "df['region'] = df['iso3'].apply(get_region)"
      ],
      "metadata": {
        "id": "dy-m9B8neJ1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unique Regions created:\", df['region'].unique())\n",
        "print(\"\\nSample of Data:\")\n",
        "print(df[['country', 'iso3', 'region']].head())"
      ],
      "metadata": {
        "id": "_RN1KGy0eNs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRest of World count:\", df[df['region'] == 'Rest of World'].shape[0])\n",
        "\n",
        "# Save for next steps (simulated persistence)\n",
        "df.to_csv('hdi_data_processed.csv', index=False)\n",
        "print(\"\\nProcessed file saved as 'hdi_data_processed.csv'\")"
      ],
      "metadata": {
        "id": "xuqKIwNHeRHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2: Data Exploration"
      ],
      "metadata": {
        "id": "d4XijucsrjL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"hdi_data_processed.csv\")\n",
        "\n",
        "# 2. Filter for the year 2022\n",
        "df_2022 = df[df['year'] == 2022].copy()"
      ],
      "metadata": {
        "id": "Af6hd9RzW0na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Shape of 2022 Dataset ---\")\n",
        "print(df_2022.shape)\n",
        "\n",
        "print(\"\\n--- Columns & Data Types ---\")\n",
        "print(df_2022.info())\n",
        "\n",
        "print(\"\\n--- First 5 Rows ---\")\n",
        "print(df_2022.head())"
      ],
      "metadata": {
        "id": "RZjVLwkTemq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_cols = ['country', 'hdi', 'life_expectancy', 'mean_yr_school', 'gross_inc_percap']\n",
        "missing_cols = [col for col in key_cols if col not in df_2022.columns]\n",
        "\n",
        "if missing_cols:\n",
        "    print(f\"\\n[WARNING] Missing key columns: {missing_cols}\")\n",
        "else:\n",
        "    print(\"\\n[SUCCESS] All key columns for HDI analysis are present.\")\n",
        "\n",
        "# 5. Save the 2022 snapshot for downstream tasks\n",
        "df_2022.to_csv(\"hdi_2022_df.csv\", index=False)\n",
        "print(\"\\nFile saved: 'hdi_2022_df.csv'\")"
      ],
      "metadata": {
        "id": "sdbKPEaResp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3: Missing Values & Data Cleaning"
      ],
      "metadata": {
        "id": "ZYIW3g2_rv-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2022 = pd.read_csv(\"hdi_2022_df.csv\")"
      ],
      "metadata": {
        "id": "-NfiHSMcfCgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Missing Values Count per Column ---\")\n",
        "missing_counts = df_2022.isnull().sum()\n",
        "print(missing_counts[missing_counts > 0])"
      ],
      "metadata": {
        "id": "EEXrsGdCfFch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_hdi_countries = df_2022[df_2022['hdi'].isnull()]['country'].tolist()\n",
        "print(f\"\\nCountries with missing HDI: {missing_hdi_countries}\")\n",
        "\n",
        "# Action: Drop rows where HDI is missing\n",
        "df_clean = df_2022.dropna(subset=['hdi']).copy()\n",
        "print(f\"Dropped {len(missing_hdi_countries)} rows. New shape: {df_clean.shape}\")"
      ],
      "metadata": {
        "id": "m8vItbAgfJP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicates = df_clean.duplicated(subset=['iso3']).sum()\n",
        "if duplicates > 0:\n",
        "    print(f\"\\n[WARNING] Found {duplicates} duplicate ISO3 codes. Removing duplicates...\")\n",
        "    df_clean = df_clean.drop_duplicates(subset=['iso3'])\n",
        "else:\n",
        "    print(\"\\n[SUCCESS] No duplicate countries found.\")"
      ],
      "metadata": {
        "id": "h6OTeY6YfNxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_missing = df_clean[['life_expectancy', 'mean_yr_school', 'gross_inc_percap']].isnull().sum()\n",
        "if remaining_missing.sum() > 0:\n",
        "    print(\"\\n[NOTE] Remaining missing values in sub-components:\")\n",
        "    print(remaining_missing[remaining_missing > 0])\n",
        "    # Simple Imputation: Fill with column mean (or region median if we were more advanced, but mean is standard for this level)\n",
        "    # However, usually HDI calculation requires these. If they are missing but HDI is present, it's odd.\n",
        "    # Let's inspect.\n",
        "    print(df_clean[df_clean['mean_yr_school'].isnull()][['country', 'hdi', 'mean_yr_school']])\n",
        "else:\n",
        "    print(\"\\n[SUCCESS] No missing values in key sub-components for HDI-ranked countries.\")\n",
        "\n",
        "# 6. Save cleaned data\n",
        "df_clean.to_csv(\"hdi_2022_cleaned.csv\", index=False)\n",
        "print(\"\\nFile saved: 'hdi_2022_cleaned.csv'\")"
      ],
      "metadata": {
        "id": "3n7WA0FxfSE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4: Basic Statistics"
      ],
      "metadata": {
        "id": "Gs8e1S4crzQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = pd.read_csv(\"hdi_2022_cleaned.csv\")"
      ],
      "metadata": {
        "id": "bMiqbwGmflHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats_cols = ['hdi', 'life_expectancy', 'mean_yr_school', 'gross_inc_percap']\n",
        "desc_stats = df_clean[stats_cols].describe().T[['count', 'mean', 'std', 'min', '50%', 'max']]\n",
        "desc_stats.rename(columns={'50%': 'median'}, inplace=True)\n",
        "\n",
        "print(\"--- Descriptive Statistics (2022) ---\")\n",
        "print(desc_stats)"
      ],
      "metadata": {
        "id": "Chy6RNMTfpVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_high_hdi = df_clean[df_clean['hdi'] > 0.8].copy()\n",
        "num_high_hdi = len(df_high_hdi)\n",
        "\n",
        "print(f\"\\nNumber of countries with HDI > 0.8: {num_high_hdi}\")\n",
        "print(f\"Percentage of countries with HDI > 0.8: {(num_high_hdi / len(df_clean)) * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "zKtBFgZuftQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_10 = df_clean.sort_values(by='hdi', ascending=False).head(10)[['country', 'hdi', 'region']]\n",
        "print(\"\\n--- Top 10 Countries by HDI (2022) ---\")\n",
        "print(top_10)"
      ],
      "metadata": {
        "id": "7QtquP0XfwZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bottom_5 = df_clean.sort_values(by='hdi', ascending=True).head(5)[['country', 'hdi', 'region']]\n",
        "print(\"\\n--- Bottom 5 Countries by HDI (2022) ---\")\n",
        "print(bottom_5)"
      ],
      "metadata": {
        "id": "rQQxP97_fzGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc_stats.to_csv(\"hdi_2022_stats_summary.csv\")\n",
        "print(\"\\nFile saved: 'hdi_2022_stats_summary.csv'\")"
      ],
      "metadata": {
        "id": "NAoZ5dkHf1-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"hdi_2022_cleaned.csv\")"
      ],
      "metadata": {
        "id": "uMrc71jugJ0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5: Filtering and Sorting"
      ],
      "metadata": {
        "id": "rHbwVKhUr2Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_hdi(hdi):\n",
        "    if hdi < 0.550:\n",
        "        return 'Low Human Development'\n",
        "    elif hdi < 0.700:\n",
        "        return 'Medium Human Development'\n",
        "    elif hdi < 0.800:\n",
        "        return 'High Human Development'\n",
        "    else:\n",
        "        return 'Very High Human Development'"
      ],
      "metadata": {
        "id": "_bIpjAcvgO_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['hdi_category'] = df['hdi'].apply(classify_hdi)\n",
        "\n",
        "# 3. Analyze the Distribution of Categories\n",
        "category_counts = df['hdi_category'].value_counts().reindex([\n",
        "    'Low Human Development',\n",
        "    'Medium Human Development',\n",
        "    'High Human Development',\n",
        "    'Very High Human Development'\n",
        "])"
      ],
      "metadata": {
        "id": "777mh9EDgSmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- HDI Category Counts (2022) ---\")\n",
        "print(category_counts)"
      ],
      "metadata": {
        "id": "5nUHnXIbgWDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"HDI_category_added.csv\", index=False)\n",
        "print(\"\\nFile saved: 'HDI_category_added.csv'\")\n",
        "\n",
        "# 5. Visualizations\n",
        "plt.figure(figsize=(12, 5))"
      ],
      "metadata": {
        "id": "L_XpAQefgZpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "sns.barplot(x=category_counts.index, y=category_counts.values, palette=\"viridis\")\n",
        "plt.title('Count of Countries by HDI Category (2022)')\n",
        "plt.xlabel('HDI Category')\n",
        "plt.ylabel('Number of Countries')\n",
        "plt.xticks(rotation=45, ha='right')"
      ],
      "metadata": {
        "id": "SQnxDJMZgcYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df['hdi'], bins=20, kde=True, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribution of HDI Values (2022)')\n",
        "plt.xlabel('HDI Value')\n",
        "plt.ylabel('Frequency')"
      ],
      "metadata": {
        "id": "5ioLqJYngfrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.tight_layout()\n",
        "plt.savefig('task_1a_5_hdi_distribution.png')\n",
        "print(\"\\nPlot saved: 'task_1a_5_hdi_distribution.png'\")\n",
        "# Note: User cannot see the plot directly here, I will describe it."
      ],
      "metadata": {
        "id": "TrEiK2Eiginx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 6: HDI Category Classification"
      ],
      "metadata": {
        "id": "VMpCU2mTr3KE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 2. Problem 1B – HDI Trend Analysis (2020–2022)\n"
      ],
      "metadata": {
        "id": "tHZTypCOrUJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"hdi_data_processed.csv\")\n",
        "\n",
        "# 2. Filter for the trend years (2020, 2021, 2022)\n",
        "trend_years = [2020, 2021, 2022]\n",
        "df_trend = df[df['year'].isin(trend_years)].copy()"
      ],
      "metadata": {
        "id": "IkpsPE4ggwV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_counts = df_trend.groupby('country')['year'].count()\n",
        "valid_countries = country_counts[country_counts == 3].index.tolist()"
      ],
      "metadata": {
        "id": "3xnZ9yyEgzsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trend_consistent = df_trend[df_trend['country'].isin(valid_countries)].copy()\n",
        "\n",
        "print(f\"Original Country Count: {df['country'].nunique()}\")\n",
        "print(f\"Countries with full 2020-2022 data: {len(valid_countries)}\")"
      ],
      "metadata": {
        "id": "ZHNmrf1zg3Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_trend_consistent = df_trend_consistent.sort_values(by=['country', 'year'])\n",
        "\n",
        "# 5. Save the trend dataset\n",
        "df_trend_consistent.to_csv(\"hdi_trend_df.csv\", index=False)\n",
        "print(\"\\nFile saved: 'hdi_trend_df.csv'\")\n",
        "print(\"\\n--- Sample of Trend Data ---\")\n",
        "print(df_trend_consistent[['country', 'year', 'hdi']].head(6))"
      ],
      "metadata": {
        "id": "DxmIGhMNg7CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 3. Problem 2 – Advanced HDI Exploration (South Asia)\n"
      ],
      "metadata": {
        "id": "z-c-nyizrWc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_trend = pd.read_csv(\"hdi_trend_df.csv\")\n",
        "df_pivot = df_trend.pivot(index=['country', 'region', 'iso3'], columns='year', values='hdi').reset_index()"
      ],
      "metadata": {
        "id": "BDPA7g3hhOM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot.columns.name = None\n",
        "df_pivot.rename(columns={2020: 'hdi_2020', 2021: 'hdi_2021', 2022: 'hdi_2022'}, inplace=True)"
      ],
      "metadata": {
        "id": "qyk2iUYchVpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot['hdi_change_abs'] = df_pivot['hdi_2022'] - df_pivot['hdi_2020']\n",
        "df_pivot['hdi_pct_change'] = ((df_pivot['hdi_2022'] - df_pivot['hdi_2020']) / df_pivot['hdi_2020']) * 100\n",
        "df_sorted = df_pivot.sort_values(by='hdi_pct_change', ascending=False)"
      ],
      "metadata": {
        "id": "H0T5jlE4hijs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Top 5 Countries with Positive HDI Growth (2020-2022) ---\")\n",
        "print(df_sorted[['country', 'region', 'hdi_2020', 'hdi_2022', 'hdi_pct_change']].head(5))\n",
        "\n",
        "print(\"\\n--- Bottom 5 Countries (Negative Growth) ---\")\n",
        "print(df_sorted[['country', 'region', 'hdi_2020', 'hdi_2022', 'hdi_pct_change']].tail(5))"
      ],
      "metadata": {
        "id": "bicRm5FEhoRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pivot.to_csv(\"hdi_growth_analysis.csv\", index=False)\n",
        "print(\"\\nFile saved: 'hdi_growth_analysis.csv'\")"
      ],
      "metadata": {
        "id": "fmbF6GTihsa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4. Problem 3 – Comparative Regional Analysis (South Asia vs Middle East)"
      ],
      "metadata": {
        "id": "VL6OREdWrY_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_trend = pd.read_csv(\"hdi_trend_df.csv\")\n",
        "global_trend = df_trend.groupby('year')['hdi'].mean().reset_index()"
      ],
      "metadata": {
        "id": "4hcdwXS7h90r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.lineplot(data=global_trend, x='year', y='hdi', marker='o', color='b', linewidth=2.5)\n",
        "plt.title('Global Average HDI Trend (2020-2022)')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Average HDI')\n",
        "plt.xticks([2020, 2021, 2022])  # Ensure integer ticks for years\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_1b_3_global_trend.png')\n",
        "print(\"Plot saved: 'task_1b_3_global_trend.png'\")"
      ],
      "metadata": {
        "id": "r6YJJcjHiCAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Visualization 2: Regional HDI Trend (Bar Chart)\n",
        "# Group by Region and Year\n",
        "region_trend = df_trend.groupby(['region', 'year'])['hdi'].mean().reset_index()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=region_trend, x='region', y='hdi', hue='year', palette='muted')\n",
        "plt.title('Average HDI by Region (2020-2022)')\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Average HDI')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.legend(title='Year', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_1b_3_region_trend.png')\n",
        "print(\"Plot saved: 'task_1b_3_region_trend.png'\")"
      ],
      "metadata": {
        "id": "_pgAtejPiIYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Global Average HDI Values ---\")\n",
        "print(global_trend)\n",
        "\n",
        "print(\"\\n--- Regional Averages (2022) ---\")\n",
        "print(region_trend[region_trend['year'] == 2022].sort_values(by='hdi', ascending=False))"
      ],
      "metadata": {
        "id": "_EuTiYMRiNig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2-1: South Asia Filtering & Setup\n",
        "df = pd.read_csv(\"hdi_2022_cleaned.csv\")\n",
        "\n",
        "# 2. Filter for South Asia\n",
        "# We created the 'region' column in Task 1A-1.\n",
        "df_sa = df[df['region'] == 'South Asia'].copy()\n",
        "\n",
        "# 3. Validation: List countries found\n",
        "print(\"--- South Asian Countries Identified ---\")\n",
        "sa_countries = df_sa['country'].unique()\n",
        "print(sa_countries)\n",
        "print(f\"Total Count: {len(sa_countries)}\")\n",
        "\n",
        "# 4. Check for key columns specific to Problem 2\n",
        "# Problem 2 mentions calculating a composite score using Life Expectancy and GNI per capita.\n",
        "# Ensure these columns are clean for this subset.\n",
        "print(\"\\n--- Missing Values in South Asia Subset ---\")\n",
        "print(df_sa[['life_expectancy', 'gross_inc_percap']].isnull().sum())\n",
        "\n",
        "# 5. Save the South Asia subset\n",
        "df_sa.to_csv(\"HDI_SouthAsia.csv\", index=False)\n",
        "print(\"\\nFile saved: 'HDI_SouthAsia.csv'\")"
      ],
      "metadata": {
        "id": "wLeZs_A7iuuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2-2: Composite Score Calculation (Manual Formula)\n",
        "\n",
        "# 1. Load datasets\n",
        "# We need the global dataset to define the min/max for normalization (Observed Goalposts)\n",
        "df_global = pd.read_csv(\"hdi_2022_cleaned.csv\")\n",
        "df_sa = pd.read_csv(\"HDI_SouthAsia.csv\")\n",
        "\n",
        "# 2. Define Goalposts (Observed Global Min/Max)\n",
        "# This ensures indices are between 0 and 1 relative to the world in 2022.\n",
        "le_min = df_global['life_expectancy'].min()\n",
        "le_max = df_global['life_expectancy'].max()\n",
        "\n",
        "gni_min = df_global['gross_inc_percap'].min()\n",
        "gni_max = df_global['gross_inc_percap'].max()\n",
        "\n",
        "print(f\"Goalposts (Observed 2022):\\n LE: {le_min}-{le_max}\\n GNI: {gni_min}-{gni_max}\")\n",
        "\n",
        "# 3. Calculate Indices for South Asia\n",
        "# Life Expectancy Index\n",
        "df_sa['le_index'] = (df_sa['life_expectancy'] - le_min) / (le_max - le_min)\n",
        "\n",
        "# Income Index (Logarithmic scale for Income)\n",
        "# Note: HDI standard uses log for income.\n",
        "df_sa['gni_index'] = (np.log(df_sa['gross_inc_percap']) - np.log(gni_min)) / \\\n",
        "                     (np.log(gni_max) - np.log(gni_min))\n",
        "\n",
        "# 4. Calculate Composite Score\n",
        "# Formula: 0.3 * LE_Index + 0.3 * GNI_Index\n",
        "df_sa['composite_score'] = 0.3 * df_sa['le_index'] + 0.3 * df_sa['gni_index']\n",
        "\n",
        "# 5. Rank Countries by Composite Score\n",
        "df_sa_sorted = df_sa.sort_values(by='composite_score', ascending=False)\n",
        "\n",
        "# 6. Display Result\n",
        "print(\"\\n--- South Asia: Composite Score Ranking ---\")\n",
        "print(df_sa_sorted[['country', 'hdi', 'le_index', 'gni_index', 'composite_score']])\n",
        "\n",
        "# 7. Save result\n",
        "df_sa_sorted.to_csv(\"HDI_SouthAsia_Composite.csv\", index=False)\n",
        "print(\"\\nFile saved: 'HDI_SouthAsia_Composite.csv'\")"
      ],
      "metadata": {
        "id": "kLilw56YjFph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2-3: Outlier Analysis (South Asia)\n",
        "\n",
        "# 1. Load the composite score dataset\n",
        "df_sa = pd.read_csv(\"HDI_SouthAsia_Composite.csv\")\n",
        "\n",
        "# 2. Calculate IQR (Interquartile Range) to mathematically identify outliers\n",
        "Q1 = df_sa['composite_score'].quantile(0.25)\n",
        "Q3 = df_sa['composite_score'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df_sa[(df_sa['composite_score'] < lower_bound) | (df_sa['composite_score'] > upper_bound)]\n",
        "\n",
        "print(\"--- Outlier Detection Statistics ---\")\n",
        "print(f\"Q1: {Q1:.4f} | Q3: {Q3:.4f} | IQR: {IQR:.4f}\")\n",
        "print(f\"Bounds: {lower_bound:.4f} to {upper_bound:.4f}\")\n",
        "\n",
        "if not outliers.empty:\n",
        "    print(\"\\n[ALERT] Outliers Detected:\")\n",
        "    print(outliers[['country', 'composite_score']])\n",
        "else:\n",
        "    print(\"\\n[RESULT] No mathematical outliers detected in South Asia based on 1.5*IQR.\")\n",
        "\n",
        "# 3. Visualization: Boxplot\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=df_sa['composite_score'], color='orange')\n",
        "plt.title('Distribution of Composite Scores in South Asia (Outlier Check)')\n",
        "plt.xlabel('Composite Score')\n",
        "\n",
        "# Annotate countries on the plot (swarmplot overlay to show individual points)\n",
        "sns.swarmplot(x=df_sa['composite_score'], color='black', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_2_3_outliers.png')\n",
        "print(\"\\nPlot saved: 'task_2_3_outliers.png'\")"
      ],
      "metadata": {
        "id": "Tei1nhnqjTTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2-4: Development Gap Analysis\n",
        "\n",
        "# 1. Load the composite score dataset\n",
        "df_sa = pd.read_csv(\"HDI_SouthAsia_Composite.csv\")\n",
        "\n",
        "# 2. Identify Top and Bottom Countries\n",
        "top_country = df_sa.iloc[0]\n",
        "bottom_country = df_sa.iloc[-1]\n",
        "\n",
        "print(\"--- Development Gap Analysis (South Asia) ---\")\n",
        "print(f\"Top Performer: {top_country['country']}\")\n",
        "print(f\"Bottom Performer: {bottom_country['country']}\")\n",
        "\n",
        "# 3. Calculate Gaps (Raw Values)\n",
        "gap_composite = top_country['composite_score'] - bottom_country['composite_score']\n",
        "gap_le = top_country['life_expectancy'] - bottom_country['life_expectancy']\n",
        "gap_gni = top_country['gross_inc_percap'] - bottom_country['gross_inc_percap']\n",
        "\n",
        "print(f\"\\nGap in Composite Score: {gap_composite:.4f}\")\n",
        "print(f\"Gap in Life Expectancy: {gap_le:.1f} years\")\n",
        "print(f\"Gap in GNI per Capita: ${gap_gni:,.2f}\")\n",
        "\n",
        "# 4. Visualization: Comparison of Indices\n",
        "# Prepare data for plotting\n",
        "comparison_df = df_sa.iloc[[0, -1]].copy()\n",
        "comparison_melted = comparison_df.melt(id_vars='country',\n",
        "                                       value_vars=['le_index', 'gni_index', 'composite_score'],\n",
        "                                       var_name='Metric', value_name='Score')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=comparison_melted, x='Metric', y='Score', hue='country', palette='coolwarm')\n",
        "plt.title(f'Development Gap: {top_country[\"country\"]} vs {bottom_country[\"country\"]}')\n",
        "plt.ylabel('Normalized Score (0-1)')\n",
        "plt.xlabel('Development Metric')\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Add value labels\n",
        "for p in plt.gca().patches:\n",
        "    plt.gca().annotate(f'{p.get_height():.2f}',\n",
        "                       (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                       ha='center', va='center', xytext=(0, 9),\n",
        "                       textcoords='offset points')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_2_4_gap_analysis.png')\n",
        "print(\"\\nPlot saved: 'task_2_4_gap_analysis.png'\")"
      ],
      "metadata": {
        "id": "RrPsYrycjoHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3-1: Middle East Filtering & Merging\n",
        "\n",
        "# 1. Load the cleaned 2022 dataset\n",
        "df = pd.read_csv(\"hdi_2022_cleaned.csv\")\n",
        "\n",
        "# 2. Filter for South Asia and Middle East\n",
        "regions_of_interest = ['South Asia', 'Middle East']\n",
        "df_comparative = df[df['region'].isin(regions_of_interest)].copy()\n",
        "\n",
        "# 3. Validation\n",
        "print(\"--- Region Counts in Comparative Dataset ---\")\n",
        "print(df_comparative['region'].value_counts())\n",
        "\n",
        "# 4. List countries to ensure coverage\n",
        "print(\"\\n--- Middle East Countries Included ---\")\n",
        "print(df_comparative[df_comparative['region'] == 'Middle East']['country'].unique())\n",
        "\n",
        "print(\"\\n--- South Asia Countries Included ---\")\n",
        "print(df_comparative[df_comparative['region'] == 'South Asia']['country'].unique())\n",
        "\n",
        "# 5. Save the comparative dataset\n",
        "df_comparative.to_csv(\"hdi_comparative_regions.csv\", index=False)\n",
        "print(\"\\nFile saved: 'hdi_comparative_regions.csv'\")"
      ],
      "metadata": {
        "id": "m1tkpcLmj5Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3-2: Comparative Descriptive Statistics\n",
        "\n",
        "# 1. Load the comparative dataset\n",
        "df_comp = pd.read_csv(\"hdi_comparative_regions.csv\")\n",
        "\n",
        "# 2. Group by Region and Calculate Stats\n",
        "stats_comp = df_comp.groupby('region')[['hdi', 'life_expectancy', 'gross_inc_percap']].describe().T\n",
        "\n",
        "print(\"--- Comparative Statistics: South Asia vs Middle East (2022) ---\")\n",
        "print(stats_comp)\n",
        "\n",
        "# 3. Specific Insight: Mean Differences\n",
        "means = df_comp.groupby('region')[['hdi', 'life_expectancy', 'gross_inc_percap']].mean()\n",
        "print(\"\\n--- Mean Values Comparison ---\")\n",
        "print(means)\n",
        "\n",
        "# Calculate Percentage Difference\n",
        "pct_diff_hdi = ((means.loc['Middle East', 'hdi'] - means.loc['South Asia', 'hdi']) / means.loc['South Asia', 'hdi']) * 100\n",
        "print(f\"\\nMiddle East HDI is {pct_diff_hdi:.2f}% higher than South Asia.\")\n",
        "\n",
        "# 4. Save stats to CSV\n",
        "stats_comp.to_csv(\"hdi_comparative_stats.csv\")\n",
        "print(\"\\nFile saved: 'hdi_comparative_stats.csv'\")"
      ],
      "metadata": {
        "id": "KoQM3a6nkENL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3-3: Comparative Visualization of Disparities\n",
        "\n",
        "# 1. Load the comparative dataset\n",
        "df_comp = pd.read_csv(\"hdi_comparative_regions.csv\")\n",
        "\n",
        "# 2. Set up the plotting grid\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot 1: Boxplot of HDI Distribution\n",
        "sns.boxplot(data=df_comp, x='region', y='hdi', palette='Set2', ax=axes[0])\n",
        "sns.swarmplot(data=df_comp, x='region', y='hdi', color='black', alpha=0.5, ax=axes[0]) # Add points\n",
        "axes[0].set_title('Comparison of HDI Distribution')\n",
        "axes[0].set_xlabel('Region')\n",
        "axes[0].set_ylabel('HDI Value')\n",
        "\n",
        "# Plot 2: Boxplot of GNI per Capita (Income)\n",
        "sns.boxplot(data=df_comp, x='region', y='gross_inc_percap', palette='Set2', ax=axes[1])\n",
        "sns.swarmplot(data=df_comp, x='region', y='gross_inc_percap', color='black', alpha=0.5, ax=axes[1])\n",
        "axes[1].set_title('Comparison of GNI per Capita')\n",
        "axes[1].set_xlabel('Region')\n",
        "axes[1].set_ylabel('GNI per Capita ($)')\n",
        "\n",
        "# Plot 3: Scatter Plot (Life Expectancy vs. Income)\n",
        "sns.scatterplot(data=df_comp, x='gross_inc_percap', y='life_expectancy',\n",
        "                hue='region', style='region', s=100, palette='Set2', ax=axes[2])\n",
        "axes[2].set_title('Life Expectancy vs. Income')\n",
        "axes[2].set_xlabel('GNI per Capita ($)')\n",
        "axes[2].set_ylabel('Life Expectancy (Years)')\n",
        "axes[2].grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('task_3_3_comparative_visuals.png')\n",
        "print(\"Plot saved: 'task_3_3_comparative_visuals.png'\")"
      ],
      "metadata": {
        "id": "FAlhr6tFkcTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}